{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries for further usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# computational needs\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "# scraping for data\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "# plotting\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# local files\n",
    "import tools\n",
    "\n",
    "# others\n",
    "from unidecode import unidecode\n",
    "import random, json\n",
    "import numpy as np, numpy.random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "useful methods for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "MAX_JOBS_REFUGEES = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_potential( each):\n",
    "    \"\"\"Given a city, give the number of jobs found there.\"\"\"\n",
    "    \n",
    "    # get the url for each city\n",
    "    URL = \"https://tr.indeed.com/jobs?l=\"+unidecode(each)    \n",
    "    \n",
    "    # extract the html, the values from the search\n",
    "    soup = BeautifulSoup(urllib.request.urlopen(URL).read(), 'html.parser')\n",
    "    values = soup.find(\"div\", id=\"JOB_TYPE_rbo\")\n",
    "    \n",
    "    # find total jobs found in this city\n",
    "    if values == None: # if no job was found, skip\n",
    "        return 0\n",
    "    count = 0\n",
    "    for li in values.find_all(\"li\"):\n",
    "        found_jobs = li.find(\"span\", attrs={'class':\"rbCount\"}).text\n",
    "        count += int( found_jobs[1:-1])\n",
    "    return count\n",
    "\n",
    "def update_info():\n",
    "    \"\"\"information about the job market in a all cities\"\"\"\n",
    "\n",
    "    info = {}\n",
    "    for n in G.nodes:\n",
    "        # each refugee working knows 10 job openings\n",
    "        jobs_info = 10 * G.nodes[n]['jobs_to_refugees']/G.nodes[n]['jobs']\n",
    "        if jobs_info < 1 and jobs_info > 0.5:\n",
    "            info[n] = jobs_info\n",
    "        elif jobs_info <=0.5:\n",
    "            info[n] = 0.5\n",
    "        else:\n",
    "            info[n] = 1.0\n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read City and Road data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get city data from the two sources\n",
    "cities  = pd.read_csv('tr.csv')\n",
    "cities2 = pd.read_csv('city_data.csv',\"\\t\")\n",
    "cities.fillna(0, inplace=True)\n",
    "# fix the Istanbul instance for later consistency\n",
    "cities['city'][0] = 'İstanbul'\n",
    "\n",
    "# merge the two data\n",
    "city_data = pd.merge( cities, cities2, \n",
    "                     how='outer', left_on='city', right_on='Name')\n",
    "# filter the columns you want\n",
    "cities = city_data[['city','admin','Abbr.','lat','lng','Area(km²)',\n",
    "                    'population', 'Population Estimate (E)2018-12-31']]\n",
    "# rename the column\n",
    "cities = cities.fillna('0').rename(columns={'Population Estimate (E)2018-12-31':'population2'}).iloc[:-2]\n",
    "cities['population2'] = [ int(n.replace(\",\",\"\")) for n in list(cities['population2'])]\n",
    "cities['area'] = [ int(n.replace(\",\",\"\")) for n in list(cities['Area(km²)'])]\n",
    "cities['population'] = cities['population'].where( cities['population'] > 0, cities['population2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get main roads in Turkey\n",
    "main_roads = tools.get_cities_in_main_roads()\n",
    "\n",
    "# cities to take in consideration\n",
    "main_cities = list(cities[ cities['city'] == cities['admin']]['city'])\n",
    "city_in_main_road = list(set( sum(main_roads, [])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put these cities in the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put everything in a graph\n",
    "G = nx.Graph()\n",
    "\n",
    "all_cities = set( main_cities + city_in_main_road)\n",
    "# create each city\n",
    "for city in all_cities:\n",
    "    \n",
    "    # get number of jobs for this city\n",
    "    job_potential = get_job_potential( city)\n",
    "    \n",
    "    # find position of city in map\n",
    "    city_properties = cities[cities['city'] == city].iloc[0]\n",
    "    \n",
    "    # add the city to the graph\n",
    "    G.add_node(city_properties['city'], \n",
    "               pos=( city_properties['lat'], city_properties['lng']), \n",
    "               size= int(city_properties['population']),\n",
    "               area= int(city_properties['area']) if int(city_properties['area']) != 0 else 20000, \n",
    "               refugees=0, jobs_to_refugees=0,\n",
    "               jobs=job_potential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect the cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the edges connecting the cities\n",
    "\n",
    "# if found city in road, but not in data, fix manually\n",
    "for road in main_roads:\n",
    "    \n",
    "    # if any of the paths is not in the list, then mention it, fix it manually\n",
    "    for each in road:\n",
    "        if each not in list(cities['city']):\n",
    "            print(\"City not found in list: \",each) # TODO: deal automatically\n",
    "            \n",
    "    # remind the cities that are present\n",
    "    for i in range(len(road)-1):\n",
    "        # add a connection between each two cities\n",
    "        G.add_edge( road[i], road[i+1], weight=10)\n",
    "        \n",
    "# connect the cities not in the list with the closest city in the list\n",
    "not_found = set( main_cities)-set( city_in_main_road)\n",
    "\n",
    "for each in not_found:\n",
    "    city = cities[ cities['city'] == each].iloc[0]\n",
    "    \n",
    "    # order cities present in list by distance to this city\n",
    "    found = cities[cities['city'].isin( all_cities)]\n",
    "    found['distance'] = ((found['lat']-city['lat'])**2 + (found['lng']-city['lng'])**2)\n",
    "    closest_city = found.sort_values('distance').iloc[1]['city'] # get the closest\n",
    "    \n",
    "    # add road connecting these cities\n",
    "    G.add_edge( city['city'], closest_city, weight=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the zone where the refugees enter, connect those cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the zone where the refugees enter\n",
    "# entrance dates for the refugees\n",
    "entrance_freq = pd.read_json(\"syrian_refugees.json\")\n",
    "\n",
    "# suggest area from Adana to Van\n",
    "max_lat = cities[cities['city'] ==  'Van']['lat'].iloc[0]\n",
    "max_lng = cities[cities['city'] ==  'Van']['lng'].iloc[0]\n",
    "min_lng = cities[cities['city'] =='Adana']['lng'].iloc[0]\n",
    "\n",
    "# filter\n",
    "syrian_zone = list(cities[ ( cities[ 'lng'] <= max_lng) & \n",
    "                           ( cities[ 'lng'] >= min_lng) & \n",
    "                           ( cities[ 'lat'] <= max_lat) & \n",
    "                           ( cities['city'] == cities['admin'])]['city'])\n",
    "\n",
    "# connect all cities close to Syria with the closest cities in this area\n",
    "for each in syrian_zone:\n",
    "    \n",
    "    city = cities[ cities['city'] == each].iloc[0]\n",
    "    \n",
    "    # order cities present in list by distance to this city\n",
    "    found = cities[cities['city'].isin( [n for n in syrian_zone if n != each])]\n",
    "    found['distance'] = ((found['lat']-city['lat'])**2 + (found['lng']-city['lng'])**2)\n",
    "    closest_cities = found.sort_values('distance') \n",
    "    \n",
    "    # add road connecting these cities\n",
    "    # keep the weight lower to suggest less people can move in between\n",
    "    G.add_edge( city['city'], closest_cities.iloc[0]['city'], weight=5)\n",
    "    G.add_edge( city['city'], closest_cities.iloc[1]['city'], weight=5)\n",
    "    G.add_edge( city['city'], closest_cities.iloc[2]['city'], weight=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Picture the map\n",
    "pos = {city:(long, lat) for (city, (lat,long)) in nx.get_node_attributes(G, 'pos').items()}\n",
    "nx.draw(G, pos, with_labels=False, node_size=10, node_color='g', edge_color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start adding refugees depending on time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working potential\n",
    "# males that are able to work are in the age range 18-59, 50% of them need a job\n",
    "# females that are able to work are in the age range 18-59, 10 % of them can deal with a job\n",
    "# what is the percentage of people able to work?\n",
    "with open( \"distribution.json\") as f:\n",
    "    d = json.load(f)\n",
    "work_percentage = (int(d['data'][0]['male_1859'])*0.5 \n",
    "                   + int(d['data'][0]['female_1859'])*0.1)/int(d['data'][0]['individuals'])\n",
    "# work_percentage = 17%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribute the refugees in the cities randomly\n",
    "distribute_refugees = np.random.dirichlet(np.ones(len(syrian_zone)),size=1)[0] *\\\n",
    "                       int( entrance_freq['individuals'].iloc[0] * work_percentage)\n",
    "refugees = [int(n) for n in distribute_refugees]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a job\n",
    "It is easier to get a job, once other refugees work in the same city (Job information). <br>\n",
    "If the city is small, the chances decrease. <br>\n",
    "If the number of refugees in the city is really high in proportion to the city's population, then your chances decrease. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(syrian_zone)):\n",
    "    n = syrian_zone[i]\n",
    "    \n",
    "    # put these people in the city\n",
    "    G.nodes[ n]['refugees'] += refugees[i]\n",
    "    \n",
    "    # get the jobs that are available for the refugees once in city\n",
    "    job_vacancy = int(MAX_JOBS_REFUGEES*G.nodes[n]['jobs']) - G.nodes[n]['jobs_to_refugees'] \n",
    "    G.nodes[n]['jobs_to_refugees'] += job_vacancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each round, for each city \n",
    "# give to the people not having a job the option to change city\n",
    "\n",
    "# refugees without jobs in Adana\n",
    "unemployed_refugees = G.nodes['Adana']['refugees'] - G.nodes['Adana']['jobs_to_refugees']\n",
    "unemployed_refugees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in all_cities:\n",
    "    # get the neighbors of this city\n",
    "    neighbors = [n for n in G.neighbors(city)] + [city]\n",
    "    info = update_info() # get the job options there\n",
    "\n",
    "    # decision: population, refugees, number of refugees employed, number of job positions\n",
    "    # refugee/area, people/area, info about jobs\n",
    "    decision = {}\n",
    "    for each in neighbors:\n",
    "        presence = G.nodes[each]['refugees']/G.nodes[each]['area']\n",
    "        density = G.nodes[each]['size']/G.nodes[each]['area']\n",
    "        jobs = info[each] * G.nodes[each]['jobs']\n",
    "        decision[each] = presence * jobs/density\n",
    "\n",
    "    # get the distribution of refugees moving out of this city\n",
    "    move_refugees = [ int(decision[n]/sum( decision.values()) * unemployed_refugees) for n in decision]\n",
    "\n",
    "    # move\n",
    "    for i in range(len(neighbors)):\n",
    "        G.nodes[n]['refugees'] += move_refugees[i]\n",
    "\n",
    "    # remove the concentration\n",
    "    G.nodes[city]['refugees'] -= sum(move_refugees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
