{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries for further usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'roads'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-af5d2d5ed7d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# local files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mroads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# others\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'roads'"
     ]
    }
   ],
   "source": [
    "# removing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# computational needs\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "# scraping for data\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "# plotting\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# local files\n",
    "import roads\n",
    "\n",
    "# others\n",
    "from unidecode import unidecode\n",
    "import random, json\n",
    "import numpy as np, numpy.random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "useful methods for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "MAX_JOBS_REFUGEES = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(seq):\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [x for x in seq if not (x in seen or seen_add(x))]\n",
    "\n",
    "def get_job_potential( each):\n",
    "    \"\"\"Given a city, give the number of jobs found there.\"\"\"\n",
    "    \n",
    "    # get the url for each city\n",
    "    URL = \"https://tr.indeed.com/jobs?l=\"+unidecode(each)    \n",
    "    \n",
    "    # extract the html, the values from the search\n",
    "    soup = BeautifulSoup(urllib.request.urlopen(URL).read(), 'html.parser')\n",
    "    values = soup.find(\"div\", id=\"JOB_TYPE_rbo\")\n",
    "    \n",
    "    # find total jobs found in this city\n",
    "    if values == None: # if no job was found, skip\n",
    "        return 0\n",
    "    count = 0\n",
    "    for li in values.find_all(\"li\"):\n",
    "        found_jobs = li.find(\"span\", attrs={'class':\"rbCount\"}).text\n",
    "        count += int( found_jobs[1:-1])\n",
    "    return count\n",
    "\n",
    "def update_info():\n",
    "    \"\"\"information about the job market in a all cities\"\"\"\n",
    "\n",
    "    info = {}\n",
    "    for n in G.nodes:\n",
    "        # each refugee working knows 10 job openings\n",
    "        jobs_info = 10 * G.nodes[n]['jobs_to_refugees']/(G.nodes[n]['jobs']+1)\n",
    "        if jobs_info < 1 and jobs_info > 0.5:\n",
    "            info[n] = jobs_info\n",
    "        elif jobs_info <=0.5:\n",
    "            info[n] = 0.5\n",
    "        else:\n",
    "            info[n] = 1.0\n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read City and Road data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = pd.read_csv(\"geo_data/cities_turkey.csv\")\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put these cities in the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put everything in a graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# create each city\n",
    "for city in list(cities['city']):\n",
    "    \n",
    "    # get number of jobs for this city\n",
    "    job_potential = 100#get_job_potential( city)\n",
    "    \n",
    "    # find position of city in map\n",
    "    city_properties = cities[cities['city'] == city].iloc[0]\n",
    "    \n",
    "    # add the city to the graph\n",
    "    G.add_node( city_properties['city'], \n",
    "               pos =    ( city_properties[ 'lat'], city_properties[ 'lng']), \n",
    "               size= int( city_properties[ 'population']),\n",
    "               area= int( city_properties[ 'Area(kmÂ²)'].replace(',','')),\n",
    "               unem= int( city_properties[ 'Unemployment']),\n",
    "               refugees=0, jobs_to_refugees=0,\n",
    "               jobs=job_potential*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect the cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the edges connecting the cities\n",
    "\n",
    "# if found city in road, but not in data, fix manually\n",
    "for road in main_roads:\n",
    "    # if any of the paths is not in the list, then mention it, fix it manually\n",
    "    for each in road:\n",
    "        if each not in list(cities['city']):\n",
    "            print(\"City not found in list: \",each) # TODO: deal automatically\n",
    "            \n",
    "    # remind the cities that are present\n",
    "    for i in range(len(road)-1):\n",
    "        # add a connection between each two cities\n",
    "        G.add_edge( road[i], road[i+1], weight=10)\n",
    "        \n",
    "# connect the cities not in the list with the closest city in the list\n",
    "not_found = set( cities['city'])- set(sum(main_roads, []))\n",
    "\n",
    "for each in not_found:\n",
    "    city = cities[ cities['city'] == each].iloc[0]\n",
    "    \n",
    "    # order cities present in list by distance to this city\n",
    "    found = cities[cities['city'].isin( all_cities)]\n",
    "    found['distance'] = ((found['lat']-city['lat'])**2 + (found['lng']-city['lng'])**2)\n",
    "    closest_city = found.sort_values('distance').iloc[1]['city'] # get the closest\n",
    "    \n",
    "    # add road connecting these cities\n",
    "    G.add_edge( city['city'], closest_city, weight=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the zone where the refugees enter, connect those cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suggest area from Adana to Van\n",
    "max_lat = cities[cities['city'] ==  'Van']['lat'].iloc[0]\n",
    "max_lng = cities[cities['city'] ==  'Van']['lng'].iloc[0]\n",
    "min_lng = cities[cities['city'] =='Adana']['lng'].iloc[0]\n",
    "\n",
    "# filter\n",
    "syrian_zone = list(cities[ ( cities[ 'lng'] <= max_lng) & \n",
    "                           ( cities[ 'lng'] >= min_lng) & \n",
    "                           ( cities[ 'lat'] <= max_lat)]['city'])\n",
    "\n",
    "# connect all cities close to Syria with the closest cities in this area\n",
    "for each in syrian_zone:\n",
    "    \n",
    "    city = cities[ cities['city'] == each].iloc[0]\n",
    "    \n",
    "    # order cities present in list by distance to this city\n",
    "    found = cities[cities['city'].isin( [n for n in syrian_zone if n != each])]\n",
    "    found['distance'] = ((found['lat']-city['lat'])**2 + (found['lng']-city['lng'])**2)\n",
    "    closest_cities = found.sort_values('distance') \n",
    "    \n",
    "    # add road connecting these cities\n",
    "    # keep the weight lower to suggest less people can move in between\n",
    "    G.add_edge( city['city'], closest_cities.iloc[0]['city'], weight=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Picture the map\n",
    "pos = {city:(long, lat) for (city, (lat,long)) in nx.get_node_attributes(G, 'pos').items()}\n",
    "nx.draw(G, pos, with_labels=False, node_size=10, node_color='g', edge_color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start adding refugees depending on time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the zone where the refugees enter\n",
    "# entrance dates for the refugees\n",
    "entries = [0]+list( pd.read_json(\"syrian_refugees.json\")['individuals'])\n",
    "plt.plot( entries)\n",
    "\n",
    "# working potential\n",
    "# males that are able to work are in the age range 18-59, 50% of them need a job\n",
    "# females that are able to work are in the age range 18-59, 10 % of them can deal with a job\n",
    "# what is the percentage of people able to work?\n",
    "with open( \"distribution.json\") as f:\n",
    "    d = json.load(f)\n",
    "work_percentage = (int(d['data'][0]['male_1859'])*0.5 \n",
    "                   + int(d['data'][0]['female_1859'])*0.1)/int(d['data'][0]['individuals'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a job\n",
    "It is easier to get a job, once other refugees work in the same city (Job information). <br>\n",
    "If the city is small, the chances decrease. <br>\n",
    "If the number of refugees in the city is really high in proportion to the city's population, then your chances decrease. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in range(1,len(entries)):\n",
    "    \n",
    "    # get the refugees difference from last run \n",
    "    diff = entries[run]-entries[run-1]\n",
    "    distribute_refugees = np.random.dirichlet(\\\n",
    "                          np.ones( len( syrian_zone)), size=1)[0] * diff\n",
    "    refugees = [int(n) for n in distribute_refugees]\n",
    "    \n",
    "    # put these people in the city\n",
    "    for i in range(len(syrian_zone)):\n",
    "        n = syrian_zone[i] # city close to syria\n",
    "        G.nodes[ n]['refugees'] += refugees[i]\n",
    "    \n",
    "    # check other cities for jobs\n",
    "    for city in all_cities:\n",
    "                \n",
    "        # get the jobs that are available for the refugees once in city\n",
    "        job_vacancy =  G.nodes[ city]['jobs'] - G.nodes[ city]['jobs_to_refugees'] \n",
    "        potential_workers = int(work_percentage*G.nodes[city]['refugees']-\\\n",
    "                                G.nodes[city]['jobs_to_refugees'])                  \n",
    "        if potential_workers > job_vacancy:\n",
    "            G.nodes[city]['jobs_to_refugees'] += job_vacancy\n",
    "        else:\n",
    "            G.nodes[city]['jobs_to_refugees'] += potential_workers\n",
    "            \n",
    "        # give to the people not having a job the option to change city\n",
    "        unemployed_refugees = int(G.nodes[city]['refugees']*work_percentage) \\\n",
    "                                - int(G.nodes[city]['jobs_to_refugees'])\n",
    "        if unemployed_refugees <=0:\n",
    "            continue\n",
    "            \n",
    "        # decision to change city: refugees, population/area, jobs, unemployment rate\n",
    "        decision = []\n",
    "        for each in all_cities:\n",
    "            presence = G.nodes[each]['refugees']\n",
    "            #density = G.nodes[each]['size'] * G.nodes[each]['unem']/100\n",
    "            density = G.nodes[each]['refugees']/G.nodes[each]['size']\n",
    "            jobs = G.nodes[each]['jobs']\n",
    "            decision.append( (each,(jobs + presence*10), density))\n",
    "\n",
    "        # sort by opportunities and density\n",
    "        sort_opp = sorted(decision, key=lambda tup: tup[1])\n",
    "        sort_den = sorted(decision, key=lambda tup: tup[2])\n",
    "        sorted_city = {}\n",
    "        for i,each in enumerate(sort_opp):\n",
    "            sorted_city[ each[0]] = i\n",
    "        for i,each in enumerate(sort_den):\n",
    "            sorted_city[ each[0]] += len(sort_den) - i\n",
    "        sorted_city = {k:v for k, v in sorted(sorted_city.items(), key=lambda item: item[1])}\n",
    "       \n",
    "        # found coefficient per person\n",
    "        per_person = sum(sorted_city.values())/unemployed_refugees\n",
    "        \n",
    "        # find refugees to move to another city\n",
    "        moved_refugees = 0\n",
    "        for i in sorted_city:\n",
    "            refugees_to_move = int( sorted_city[i]/(per_person*work_percentage))\n",
    "            G.nodes[i]['refugees'] += refugees_to_move\n",
    "            moved_refugees += refugees_to_move\n",
    "\n",
    "        # remove the concentration\n",
    "        G.nodes[city]['refugees'] -= moved_refugees\n",
    "        \n",
    "    if run%10 == 0:\n",
    "        plt.figure(run/50)\n",
    "        plt.plot([G.nodes[n]['refugees'] for n in G.nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(G)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in G.nodes:\n",
    "    print(\"City:\\t\\t\",i)\n",
    "    print(\"Refugees: \\t\",G.nodes[i]['refugees'])\n",
    "    print(\"Working: \\t\",G.nodes[i]['jobs_to_refugees'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
